import sys
import yaml

import time
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from torch.autograd import Variable
from torch.utils.data import DataLoader, Dataset
from yaml import CLoader as Loader

from src.MalConv import MalConv
from src.util import ExeDataset,write_pred

import os
cuda_no = "3"
os.environ["CUDA_VISIBLE_DEVICES"] = cuda_no

# 传入训练脚本运行所需参数：配置文件路径和随机种子
try:
    config_path = sys.argv[1]
    seed = int(sys.argv[2])
    print(config_path,seed)
    conf = yaml.load(open(config_path,'r'),Loader=Loader)
except:
    print('Usage: python3 run_exp.py <config file path> <seed>')
    sys.exit()

exp_name = conf['exp_name']+'_sd_'+str(seed)
print('Experiment:')
print('\t',exp_name)

# ------------------- 配置文件中参数读取 -----------------
# 软件样本和标签存储路径读取
train_label_path = conf['train_label_path']
test_A_label_path = conf['test_A_label_path']
test_B_label_path = conf['test_B_label_path']

train_data_path = conf['train_data_path']
test_A_data_path = conf['test_A_data_path']
test_B_data_path = conf['test_B_data_path']

# 日志、预测结果文件存储路径读取
log_dir = conf['log_dir']
pred_dir = conf['pred_dir']
checkpoint_dir = conf['checkpoint_dir']

log_file_path = log_dir+exp_name+'.log'
chkpt_acc_path = checkpoint_dir+exp_name+'.model'
pred_path = pred_dir+exp_name+'.pred'

# 模型训练相关参数读取
use_gpu = torch.cuda.is_available()
use_cpu = conf['use_cpu']
learning_rate = conf['learning_rate']   # 
max_step = conf['max_step']
test_step = conf['test_step']
batch_size = conf['batch_size']
first_n_byte = conf['first_n_byte']
window_size = conf['window_size']
display_step = conf['display_step']
sample_cnt = conf['sample_cnt']

# ----------------- 数据读取 ----------------------------
# 标签数据读取
train_label_df = pd.read_csv(train_label_path)
test_A_label_df = pd.read_csv(test_A_label_path)
test_B_label_df = pd.read_csv(test_B_label_path)

train_df = train_label_df.drop_duplicates()
test_A_df = test_A_label_df.drop_duplicates()
test_B_df = test_B_label_df.drop_duplicates()

if sample_cnt != 1:
    train_df = train_df.sample(n=sample_cnt,random_state=seed)
    test_A_df = test_A_df.sample(n=sample_cnt,random_state=seed)

print('Training Set:')
print('\tTotal',len(train_df),'files')
print('\tMalware Count :',train_df['label'].value_counts()[1])
print('\tGoodware Count:',train_df['label'].value_counts()[0])


print('Test A Set:')
print('\tTotal',len(test_A_df),'files')
print('\tMalware Count :',test_A_df['label'].value_counts()[1])
print('\tGoodware Count:',test_A_df['label'].value_counts()[0])

print('Test B Set:')
print('\tTotal',len(test_B_df),'files')
print('\tMalware Count :',test_B_df['label'].value_counts()[1])
print('\tGoodware Count:',test_B_df['label'].value_counts()[0])



# 数据加载进dataloader
print("Loading data to DataLoader....")
train_dataloader = DataLoader(
    ExeDataset(
        list(train_df.filename),
        train_data_path,
        list(train_df.label),
        first_n_byte
    ),
    batch_size=batch_size,
    shuffle=True,
    num_workers=use_cpu
)
test_A_dataloader = DataLoader(
    ExeDataset(
        list(test_A_df.filename),
        test_A_data_path,
        list(test_A_df.label),
        first_n_byte
    ),
    batch_size=batch_size,
    shuffle=True,
    num_workers=use_cpu
)

test_B_dataloader = DataLoader(
    ExeDataset(
        list(test_B_df.filename),
        test_B_data_path,
        list(test_B_df.label),
        first_n_byte
    ),
    batch_size=batch_size,
    shuffle=True,
    num_workers=use_cpu
)
valid_idx = list(test_A_df.filename)
print("Load data to DataLoader completed!")

# 加载模型
malconv = MalConv(input_length=first_n_byte,window_size=window_size)
bce_loss = nn.BCEWithLogitsLoss()
adam_optim = optim.Adam([{'params':malconv.parameters()}],lr=learning_rate)
sigmoid = nn.Sigmoid()

if use_gpu:
    malconv = malconv.cuda()
    bce_loss = bce_loss.cuda()
    sigmoid = sigmoid.cuda()


step_msg = '\tstep-{}-loss-{:.6f}-acc-{:.4f}-time-{:.2f}'
valid_msg = '\tstep-{}-train_loss-{:.6f}-train_acc-{:.4f}-val_loss-{:.6f}-val_acc-{:.4f}'
log_msg = '{}, {:.6f}, {:.4f}, {:.6f}, {:.4f}, {:.2f}'
history = {}
history['train_loss'] = []
history['train_acc'] = []

log = open(log_file_path,'w')
log.write('step,tr_loss, tr_acc, val_loss, val_acc, time\n')

valid_best_acc = 0.0
total_step = 0
step_cost_time = 0

# 模型与测试
print("Model Train Start...")
if use_gpu:
    print("Use Gpu",cuda_no)
else:
    print("Use Cpu")
while total_step < max_step:
    
    # 训练
    for step,batch_data in enumerate(train_dataloader):
        start = time.time()

        adam_optim.zero_grad()
        
        cur_batch_size = batch_data[0].size(0)
        exe_input = batch_data[0].cuda() if use_gpu else batch_data[0]
        exe_input = Variable(exe_input.long(),requires_grad=False)
        
        label = batch_data[1].cuda() if use_gpu else batch_data[1]
        label = Variable(label.float(),requires_grad=False)
        pred = malconv(exe_input)
        loss = bce_loss(pred,label)
        loss.backward()
        adam_optim.step()

        history['train_loss'].append(loss.cpu().data.numpy())
        history['train_acc'].extend(list(label.cpu().data.numpy().astype(int)==(sigmoid(pred).cpu().data.numpy()+0.5).astype(int)))
        
        step_cost_time = time.time()-start
        
        if (step+1)%display_step == 0:
            print(step_msg.format(total_step,np.mean(history['train_loss']),
                                  np.mean(history['train_acc']),step_cost_time))
        total_step += 1

        # 每训练test_step个batch，中断一次训练进行测试
        if total_step%test_step ==0:
            break
    
    
    # 测试
    print("Model Test Start...")
    history['val_loss'] = []
    history['val_acc'] = []
    history['val_pred'] = []
    for _,val_batch_data in enumerate(test_A_dataloader):
        cur_batch_size = val_batch_data[0].size(0)

        exe_input = val_batch_data[0].cuda() if use_gpu else val_batch_data[0]
        exe_input = Variable(exe_input.long(),requires_grad=False)

        label = val_batch_data[1].cuda() if use_gpu else val_batch_data[1]
        label = Variable(label.float(),requires_grad=False)

        pred = malconv(exe_input)
        loss = bce_loss(pred,label)

        history['val_loss'].append(loss.cpu().data.numpy())
        history['val_acc'].extend(list(label.cpu().data.numpy().astype(int)==(sigmoid(pred).cpu().data.numpy()+0.5).astype(int)))
        history['val_pred'].append(list(sigmoid(pred).cpu().data.numpy()))

    print(log_msg.format(total_step, np.mean(history['train_loss']), np.mean(history['train_acc']),
                    np.mean(history['val_loss']), np.mean(history['val_acc']),step_cost_time),
          file=log,flush=True)
    
    print(valid_msg.format(total_step,np.mean(history['train_loss']),np.mean(history['train_acc']),
                           np.mean(history['val_loss']),np.mean(history['val_acc'])))
    
    if valid_best_acc < np.mean(history['val_acc']):
        valid_best_acc = np.mean(history['val_acc'])
        torch.save(malconv,chkpt_acc_path)
        print('Checkpoint saved at',chkpt_acc_path)
        write_pred(history['val_pred'],valid_idx,pred_path)
        print('Prediction saved at', pred_path)

    history['train_loss'] = []
    history['train_acc'] = []