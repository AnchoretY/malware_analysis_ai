import sys
import yaml

import time
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from torch.autograd import Variable
from torch.utils.data import DataLoader, Dataset
from yaml import CLoader as Loader

from src.MalConv_multiple import MalConv
from src.util import ExeDataset_asm,write_pred

import os
cuda_no = "2"
os.environ["CUDA_VISIBLE_DEVICES"] = cuda_no

# 传入训练脚本运行所需参数：配置文件路径和随机种子
try:
    config_path = sys.argv[1]
    seed = int(sys.argv[2])
    print(config_path,seed)
    conf = yaml.load(open(config_path,'r'),Loader=Loader)
except:
    print('Usage: python3 run_exp.py <config file path> <seed>')
    sys.exit()

exp_name = conf['exp_name']+'_sd_'+str(seed)
print('Experiment:')
print('\t',exp_name)

# ------------------- 配置文件中参数读取 -----------------
# 软件样本和标签存储路径读取
train_label_path = conf['train_label_path']
test_label_path = conf['test_label_path']

train_data_path = conf['train_data_path']
test_data_path = conf['test_data_path']

# 日志、预测结果文件存储路径读取
log_dir = conf['log_dir']
pred_dir = conf['pred_dir']
checkpoint_dir = conf['checkpoint_dir']

log_file_path = log_dir+exp_name+'.log'
chkpt_acc_path = checkpoint_dir+exp_name+'.model'
pred_path = pred_dir+exp_name+'.pred'

# 模型训练相关参数读取
use_gpu = torch.cuda.is_available()
use_cpu = conf['use_cpu']
learning_rate = conf['learning_rate']   # 
max_step = conf['max_step']
test_step = conf['test_step']
batch_size = conf['batch_size']
first_n_byte = conf['first_n_byte']
window_size = conf['window_size']
display_step = conf['display_step']
sample_cnt = conf['sample_cnt']

# ----------------- 数据读取 ----------------------------
# 标签数据读取
train_label_df = pd.read_csv(train_label_path)
test_label_df = pd.read_csv(test_label_path)

train_df = train_label_df.drop_duplicates()
test_df = test_label_df.drop_duplicates()

if sample_cnt != 1:
    train_df = train_df.sample(n=sample_cnt,random_state=seed)
    test_df = test_df.sample(n=sample_cnt,random_state=seed)


famliy_dict = {}
for i,famliy_name in enumerate(train_df["famliy_name"].drop_duplicates().tolist()):
    famliy_dict[famliy_name] = i

train_df['famliy'] = train_df.apply(lambda x:famliy_dict[x.famliy_name],axis=1)
test_df['famliy'] = test_df.apply(lambda x:famliy_dict[x.famliy_name],axis=1)

print('Train Set:')
print('\tTotal',len(train_df),'files')
for famliy in train_df.famliy.drop_duplicates().tolist():
    print('\tFamliy {} sample count :{}'.format(famliy,train_df[train_df['famliy']==famliy].shape[0]))


print('Test Set:')
print('\tTotal',len(test_df),'files')
for famliy in test_df.famliy.drop_duplicates().tolist():
    print('\tFamliy {} sample count :{}'.format(famliy,test_df[test_df['famliy']==famliy].shape[0]))




# 数据加载进dataloader
print("Loading data to DataLoader....")
train_dataloader = DataLoader(
    ExeDataset_asm(
        list(train_df.filename),
        train_data_path,
        list(train_df.famliy),
        first_n_byte
    ),
    batch_size=batch_size,
    shuffle=True,
    num_workers=use_cpu
)
test_dataloader = DataLoader(
    ExeDataset_asm(
        list(test_df.filename),
        test_data_path,
        list(test_df.famliy),
        first_n_byte
    ),
    batch_size=batch_size,
    shuffle=True,
    num_workers=use_cpu
)

valid_idx = list(test_df.filename)
print("Load data to DataLoader completed!")

# 加载模型
malconv = MalConv(input_length=first_n_byte,window_size=window_size)
#bce_loss = nn.BCEWithLogitsLoss()
ce_loss = nn.CrossEntropyLoss()
adam_optim = optim.Adam([{'params':malconv.parameters()}],lr=learning_rate)
sigmoid = nn.Sigmoid()

if use_gpu:
    malconv = malconv.cuda()
    # bce_loss = bce_loss.cuda()
    ce_loss = ce_loss.cuda()
    sigmoid = sigmoid.cuda()


step_msg = '\tstep-{}-loss-{:.6f}-acc-{:.4f}-time-{:.2f}'
valid_msg = '\tstep-{}-train_loss-{:.6f}-train_acc-{:.4f}-val_loss-{:.6f}-val_acc-{:.4f}'
log_msg = '{}, {:.6f}, {:.4f}, {:.6f}, {:.4f}, {:.2f}'
history = {}
history['train_loss'] = []
history['train_acc'] = []

log = open(log_file_path,'w')
log.write('step,tr_loss, tr_acc, val_loss, val_acc, time\n')

valid_best_acc = 0.0
total_step = 0
step_cost_time = 0

# 模型与测试
print("Model Train Start...")
if use_gpu:
    print("Use Gpu",cuda_no)
else:
    print("Use Cpu")

print("Train Start...")
while total_step < max_step:
    
    # 训练
    for step,batch_data in enumerate(train_dataloader):
        start = time.time()

        adam_optim.zero_grad()
        
        cur_batch_size = batch_data[0].size(0)
        exe_input = batch_data[0].cuda() if use_gpu else batch_data[0]
        exe_input = Variable(exe_input.long(),requires_grad=False)
        
        label = batch_data[1].cuda() if use_gpu else batch_data[1]
        label = Variable(label.long(),requires_grad=False)
        label = label.squeeze()
        pred = malconv(exe_input)
        loss = ce_loss(pred,label)
        loss.backward()
        adam_optim.step()

        history['train_loss'].append(loss.cpu().data.numpy())
        pred_famliy = pred.cpu().data.max(1)[1]
        history['train_acc'].append(round(pred_famliy.eq(label.cpu().data).cpu().sum().item() / len(batch_data[0]), 4))
        
        step_cost_time = time.time()-start
        
        if (step+1)%display_step == 0:
            print(step_msg.format(total_step,np.mean(history['train_loss']),
                                  np.mean(history['train_acc']),step_cost_time))
        total_step += 1

        # 每训练test_step个batch，中断一次训练进行测试
        if total_step%test_step ==0:
            break
    
    
    # 测试
    print("Model Test Start...")
    history['val_loss'] = []
    history['val_acc'] = []
    history['val_pred'] = []
    for _,val_batch_data in enumerate(test_dataloader):
        cur_batch_size = val_batch_data[0].size(0)

        exe_input = val_batch_data[0].cuda() if use_gpu else val_batch_data[0]
        exe_input = Variable(exe_input.long(),requires_grad=False)

        label = val_batch_data[1].cuda() if use_gpu else val_batch_data[1]
        label = Variable(label.long(),requires_grad=False)
        label = label.squeeze()

        pred = malconv(exe_input)
        loss = ce_loss(pred,label)
        pred_famliy = pred.cpu().data.max(1)[1]

        history['val_loss'].append(loss.cpu().data.numpy())
        history['val_acc'].append(round(pred_famliy.eq(label.cpu().data).cpu().sum().item() / len(batch_data[0]), 4))
        history['val_pred'].append(pred_famliy.data.tolist())
        


    print(log_msg.format(total_step, np.mean(history['train_loss']), np.mean(history['train_acc']),
                    np.mean(history['val_loss']), np.mean(history['val_acc']),step_cost_time),
          file=log,flush=True)
    
    print(valid_msg.format(total_step,np.mean(history['train_loss']),np.mean(history['train_acc']),
                           np.mean(history['val_loss']),np.mean(history['val_acc'])))
    
    if valid_best_acc < np.mean(history['val_acc']):
        valid_best_acc = np.mean(history['val_acc'])
        torch.save(malconv,chkpt_acc_path)
        print('Checkpoint saved at',chkpt_acc_path)
        # def write_pred(test_pred,test_idx,file_path):
        #     test_pred = [item for sublist in test_pred for item in sublist]
        #     print(test_pred,test_idx)
        #     print("----")
        #     with open(file_path,'w') as f:
        #         for idx,pred in zip(test_idx,test_pred):
        #             print(idx,pred)
        #             print(idx.upper()+','+str(pred),file=f)
        write_pred(history['val_pred'],valid_idx,pred_path)
        print('Prediction saved at', pred_path)

    history['train_loss'] = []
    history['train_acc'] = []